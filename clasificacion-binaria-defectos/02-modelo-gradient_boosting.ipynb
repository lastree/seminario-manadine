{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Gradient Boosting\n",
    "\n",
    "Al igual que la anterior fase de limpieza e inspección, este notebook también se encontrará organizado en diferentes bloques, los cuáles son mostrados a continuación:\n",
    "\n",
    "* **BLOQUE 1**: Partición de los conjuntos de datos\n",
    "* **BLOQUE 2**: Entrenamiento del modelo con todas las variables\n",
    "* **BLOQUE 3**: Reducción del número de variables\n",
    "* **BLOQUE 4**: Ajuste de hiperparámetros y modelo final\n",
    "\n",
    "Asimismo, las primeras celdas corresponderán a la instalación y carga de las librerías necesarias para la ejecución del script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages('xgboost')\n",
    "#install.packages('caret')\n",
    "#install.packages('e1071')\n",
    "#install.packages('pROC')\n",
    "#install.packages('Ckmeans.1d.dp')\n",
    "#install.packages('ggplot2')\n",
    "#install.packages('DiagrammeR')\n",
    "\n",
    "library(xgboost)\n",
    "library(caret)\n",
    "library(e1071)\n",
    "library(pROC)\n",
    "library(Ckmeans.1d.dp)\n",
    "library(ggplot2)\n",
    "library(DiagrammeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOQUE 1: Partición de los conjuntos de datos\n",
    "En este primer bloque obtendremos los conjuntos necesarios para realizar el entrenamiento del modelo y poder observar y comparar el resultado del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del fichero .csv obtenido\n",
    "data <- read.csv(???, sep = ???, header = ???)\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta fase es la de dividir el dataset anterior en tres conjuntos distintos teniendo en cuenta que el número de observaciones entre clases es muy distinto:\n",
    "\n",
    "* Conjunto de entrenamiento -> balanceado \n",
    "* Conjunto de validación  -> balanceado\n",
    "* Conjunto de test -> no balanceado\n",
    "\n",
    "_Balanceado_ : mismo número de observaciones de cada clase\n",
    "\n",
    "El proceso a seguir es el siguiente:\n",
    "![particion_balanceo](img/particion_balanceo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera partición: Obtención del conjunto de test\n",
    "\n",
    "# Pista: la librería caret tiene funciones maravillosas para partir conjuntos de datos preservando la distribución de las clases y para hacer downsampling ^^\n",
    "df_test <- ?\n",
    "df_train <- ?\n",
    "df_valid <- ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Tamaño final de los conjuntos.\n",
    "cat('Tamaño del conjunto de entrenamiento:', nrow(df_train), '\\n')\n",
    "cat('Tamaño del conjunto de validación:', nrow(df_valid), '\\n')\n",
    "cat('Tamaño del conjunto de test:', nrow(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos de los conjuntos la variable objeto de estudio\n",
    "# Convertir en matrices, ya que la función para entrenar el modelo XGB no permite utilizar dataframes\n",
    "X_train <- as.matrix(df_train[, which(names(df_train) != ???)])\n",
    "y_train <- df_train[, ???]\n",
    "\n",
    "X_valid <- as.matrix(df_valid[, which(names(df_valid) != ???)])\n",
    "y_valid <- df_valid[, ???]\n",
    "\n",
    "X_test <- as.matrix(df_test[, which(names(df_test) != ???)])\n",
    "y_test <- df_test[, ???]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOQUE 2: Entrenamiento del modelo con todas las variables\n",
    "\n",
    "#### **¿Qué es _Boosting_?**\n",
    "\n",
    "_Boosting_ es un meta-algoritmo de aprendizaje automático que reduce el sesgo y la varianza en un contexto de aprendizaje supervisado. Consiste en combinar los resultados de varios clasificadores débiles para obtener un clasificador robusto. Cuando se añaden estos clasificadores débiles, se hace de modo que éstos tengan diferente peso en función de la exactitud de sus predicciones. Tras añadir un clasificador débil, los datos cambian su estructura de pesos: los casos mal clasificados ganan peso y los que son clasificados correctamente pierden peso. \n",
    "\n",
    "**Gradient Boosting (GB)** o _Potenciación del gradiente_ consiste en plantear el problema como una optimización numérica en el que el objetivo es minimizar una función de coste añadiendo clasificadores débiles mediante el descenso del gradiente. Involucra tres elementos:\n",
    "\n",
    "* La **función de coste** a optimizar: depende del tipo de problema a resolver.\n",
    "* Un **clasificador débil** para hacer las predicciones: por lo general se usan árboles de decisión.\n",
    "* Un **modelo que añade (ensambla) los clasificadores débiles** para minimizar la función de coste: se usa el descenso del gradiente para minimizar el coste al añadir árboles.\n",
    "\n",
    "Para este problema utilizaremos la librería _XGBoost_, que es una implementación particular muy eficiente de Gradient Boosting.\n",
    "\n",
    "Tutoriales de la librería en R:\n",
    "* https://xgboost.readthedocs.io/en/latest/R-package/xgboostPresentation.html\n",
    "* http://dmlc.github.io/rstats/2016/03/10/xgboost.html\n",
    "\n",
    "Los hiperparámetros más importantes que intervienen en este algoritmo y que aquí utilizaremos se describen a continuación:\n",
    "\n",
    "* Parámetros generales:\n",
    " * **nthread**: número de hilos paralelos usados en la ejecución.\n",
    " * **objetive**: objetivo del aprendizaje.\n",
    " * **eval_metric**: métrica de evaluación para el conjunto en cuestión.\n",
    " \n",
    " \n",
    "* Parámetros propios del _Boosting_:\n",
    " * **eta (learning rate)**: determina el impacto de cada árbol en la salida final. Se parte de una estimación inicial que se va actualizando con la salida de cada árbol. Es el parámetro que controla la magnitud de las actualizaciones.\n",
    " * **nrounds**: número de árboles a utilizar.\n",
    "\n",
    "\n",
    "* Parámetros propios de los árboles:\n",
    " * **max_depth**: profundidad máxima de un árbol.\n",
    " \n",
    "Más información sobre los parámetros y la librería en general:\n",
    "* https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params <- list(objetive = 'binary:logistic',\n",
    "               nthread = 4,\n",
    "               max_depth = 6,\n",
    "               eta = 0.3,\n",
    "               eval_metric = 'auc')\n",
    "\n",
    "xgb_model <- xgboost(data = ???, label = ???, params = ???, nrounds = 30, verbose = 1, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de cada variable en el modelo\n",
    "feature_importance <- xgb.importance(feature_names = ???, model = ???)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico con la importancia\n",
    "options(repr.plot.width = 6, repr.plot.height = 3.5)\n",
    "xgb.ggplot.importance(importance_matrix = feature_importance, rel_to_first = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ver como de bueno es nuestro modelo, podemos obtener las predicciones que realiza sobre los conjuntos de entrenamiento y validación, y realizar el cálculo de alguna métrica para observar su rendimiento. En este caso, observaremos el **área bajo la curva ROC** (más conocido simplemente como AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste/Rendimiento sobre datos de entrenamiento.\n",
    "pred_train <- predict(xgb_model, ???)\n",
    "\n",
    "# Rendimiento sobre datos de validación\n",
    "pred_valid <- predict(xgb_model, ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe con la probabilidad de ser o no defectuosa la pieza\n",
    "# y añadimos el cálculo de la predicción final\n",
    "\n",
    "# Entrenamiento\n",
    "predictions_train <- data.frame('probability' = pred_train, \n",
    "                                'prediction' = ???)\n",
    "\n",
    "# Validación\n",
    "predictions_valid <- data.frame('probability' = pred_valid, \n",
    "                                'prediction' = ???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de AUCs\n",
    "\n",
    "# Entrenamiento\n",
    "roc_train <- roc(???, predictions_train$prediction)\n",
    "auc_train <- round(auc(roc_train), 4)\n",
    "\n",
    "# Validación\n",
    "roc_valid <- roc(???, predictions_valid$prediction)\n",
    "auc_valid <- round(auc(roc_valid), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(paste('Área bajo la curva (AUC) en entrenamiento:', auc_train, '\\n'))\n",
    "cat(paste('Área bajo la curva (AUC) en validación:', auc_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOQUE 3: Reducción del número de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este bloque se estudiará si es posible reducir el número de variables a utilizar por el _Gradient Boosting_. Se trata de una fase muy importante, pues, como ya se ha visto al medir la importancia, **no todas las variables causan un impacto importante** en el modelo. Además, utilizar un menor número de variables es preferible ya que implica una **simplificación el modelo** y una mayor interpretabilidad.\n",
    "\n",
    "Para encontrar el número más óptimo de variables entrenaremos diversos modelos de manera iterativa, incorporando de una en una las variables ordenadas por importancia en el modelo. Así, almacenaremos en cada iteración los AUC tanto del conjunto de entrenamiento como de validación, y observaremos con que número de variables obtenemos un rendimiento lo suficientemente bueno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle for para obtener las AUCs del modelo según nº de variables\n",
    "auc_features <- data.frame('num_variables' = numeric(), 'auc_train' = numeric(), 'auc_valid' = numeric())\n",
    "\n",
    "for (i in 1:???){\n",
    "    cat('Entrenamiento del modelo con ', i, ' variables.\\n')\n",
    "    cat('================================================')\n",
    "    \n",
    "    # Reducción de conjuntos\n",
    "    cols <- c(feature_importance[1:i, '???'])$???\n",
    "    X_train_red <- as.matrix(X_train[, cols])\n",
    "    X_valid_red <- as.matrix(X_valid[, cols])\n",
    "    \n",
    "    # Ajuste del modelo y obtención de predicciones\n",
    "    model_red <- xgboost(data = X_train_red, label = y_train, params = params, nrounds = 30,\n",
    "                         verbose = 0, seed = 0)\n",
    "    \n",
    "    pred_train <- predict(model_red, X_train_red)\n",
    "    pred_train <- ifelse(pred_train > 0.5, 1, 0)\n",
    "    \n",
    "    pred_valid <- predict(model_red, X_valid_red)\n",
    "    pred_valid <- ifelse(pred_valid > 0.5, 1, 0)\n",
    "    \n",
    "    # AUCs\n",
    "    roc_train <- roc(y_train, pred_train)\n",
    "    auc_train <- round(auc(roc_train), 4)\n",
    "    \n",
    "    roc_valid <- roc(y_valid, pred_valid)\n",
    "    auc_valid <- round(auc(roc_valid), 4)\n",
    "    \n",
    "    # Añadimos la información al dataframe\n",
    "    auc_features[i, 'num_variables'] <- i\n",
    "    auc_features[i, 'auc_train'] <- auc_train\n",
    "    auc_features[i, 'auc_valid'] <- auc_valid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe que contiene la información del proceso iterativo\n",
    "auc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico que permite visualizar el AUC de los conjuntos según el nº de variables utilizadas\n",
    "options(repr.plot.width = 6, repr.plot.height = 3.5)\n",
    "\n",
    "p <- ggplot(data = ???)\n",
    "p <- p + geom_line(aes(x = ???, y = ???, colour = 'Entrenamiento'))\n",
    "p <- p + geom_line(aes(x = ???, y = ???, colour = 'Validación'))\n",
    "p <- p + theme_bw()\n",
    "p <- p + theme(plot.title = element_text(size = 12, hjust = 0.5, face = \"bold\", color= \"grey20\"))\n",
    "p <- p + labs(title = 'Gradient Boosting AUC según nº de variables')\n",
    "p <- p + scale_x_continuous('Número de variables', breaks = seq(1, nrow(auc_features), 1))\n",
    "p <- p + scale_y_continuous('AUC')\n",
    "p <- p + scale_color_manual('', breaks = c('Entrenamiento', 'Validación'), \n",
    "                             values = c('Entrenamiento' = 'steelblue', 'Validación' = 'darkorange'))\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de las variables a utilizar\n",
    "cols <- c(feature_importance[1:???, '???'])$???\n",
    "\n",
    "# Reducción de los conjuntos\n",
    "X_train_red <- X_train[, ???]\n",
    "X_valid_red <- X_valid[, ???]\n",
    "X_test_red <- X_test[, ???]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevo modelo con la reducción de variables\n",
    "xgb_model_red <- xgboost(data = ???, label = ???, params = ???, nrounds = 30,\n",
    "                         verbose = 0, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendimiento del modelo en conjuntos de entrenamiento y validación (AUCs)\n",
    "\n",
    "# Entrenamiento\n",
    "pred_train <- predict(xgb_model_red, X_train_red)\n",
    "pred_train <- ifelse(pred_train > 0.5, 1, 0)\n",
    "\n",
    "roc_train <- roc(y_train, pred_train)\n",
    "auc_train <- round(auc(roc_train), 4)\n",
    "\n",
    "# Validación\n",
    "pred_valid <- predict(xgb_model_red, X_valid_red)\n",
    "pred_valid <- ifelse(pred_valid > 0.5, 1, 0)\n",
    "\n",
    "roc_valid <- roc(y_valid, pred_valid)\n",
    "auc_valid <- round(auc(roc_valid), 4)\n",
    "\n",
    "# Resultados\n",
    "cat('Área bajo la curva (AUC) en entrenamiento:', auc_train, '\\n')\n",
    "cat('Área bajo la curva (AUC) en validación:', auc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOQUE 4: Ajuste de hiperparámetros y modelo final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez seleccionadas las variables a utilizar en nuestro modelo, faltaría realizar el correspondiente **ajuste de los hiperparámetros**. Estos valores deber ser establecidos antes del entrenamiento, y de su correcta elección dependerá el resultado que obtendremos.\n",
    "\n",
    "Los hiperparámetros ideales dependen del perfil de los datos que estamos analizando, por lo que no es sencillo establecer un procedimiento estándar para su obtención. En este caso realizaremos un **ajuste manual** de los mismos, observando directamente el cambio en el rendimiento del modelo aplicado a los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio en los valores de los hiperparámetros\n",
    "best_params <- list(objetive = 'binary:logistic',\n",
    "                    nthread = 4,\n",
    "                    max_depth = ???,\n",
    "                    eta = ???,\n",
    "                    eval_metric = 'auc')\n",
    "\n",
    "# Entrenamiento del modelo con los nuevos valores\n",
    "best_xgb_model <- xgboost(data = X_train_red, label = y_train, params = best_params, nrounds = ???,\n",
    "                          verbose = 0, seed = 0)\n",
    "\n",
    "# Rendimiento del nuevo modelo en los conjuntos de entrenamiento y validación\n",
    "# Entrenamiento\n",
    "new_pred_train <- predict(best_xgb_model, X_train_red)\n",
    "new_pred_train <- ifelse(new_pred_train > 0.5, 1, 0)\n",
    "\n",
    "new_roc_train <- roc(y_train, new_pred_train)\n",
    "new_auc_train <- round(auc(new_roc_train), 4)\n",
    "\n",
    "# Validación\n",
    "new_pred_valid <- predict(best_xgb_model, X_valid_red)\n",
    "new_pred_valid <- ifelse(new_pred_valid > 0.5, 1, 0)\n",
    "\n",
    "new_roc_valid <- roc(y_valid, new_pred_valid)\n",
    "new_auc_valid <- round(auc(new_roc_valid), 4)\n",
    "\n",
    "# Resultados\n",
    "cat('Nuevo área bajo la curva (AUC) en entrenamiento:', new_auc_train, '\\n')\n",
    "cat('Nuevo área bajo la curva (AUC) en validación:', new_auc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenido ya nuestro mejor modelo, podemos observar su rendimiento sobre unos datos totalmente nuevos y más reales: el conjunto de test. Para ello, además de mostrar el AUC como veníamos haciendo a lo largo del análisis, observaremos también la **matriz de confusión**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en conjunto de test\n",
    "pred_test <- predict(best_xgb_model, ???)\n",
    "pred_test <- ???\n",
    "\n",
    "# Área bajo la curva\n",
    "roc_test <- roc(???, pred_test)\n",
    "auc_test <- round(auc(roc_test), 4)\n",
    "\n",
    "cat('Área bajo la curva (AUC) en test:', auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm_test <- ???\n",
    "\n",
    "cat('Matriz de confusión para datos de test:\\n\\n')\n",
    "print(cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de obtener la matriz de confusión, junto con otras métricas\n",
    "cm_test2 <- confusionMatrix(as.factor(???), as.factor(???), mode = 'everything',\n",
    "                            positive = '1')\n",
    "cm_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible si se desea observar los árboles que son construidos en el modelo y que establecen las relaciones entre las variables utilizadas en cada uno de ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE!!: Tiempo de ejecución muy largo. Evitar ejecutar\n",
    "xgb.plot.tree(feature_names = best_xgb_model$feature_names, model = best_xgb_model, trees = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para terminar, debemos guardar nuestro modelo ya entrenado, de manera que cuando se desee utilizar solo sea necesario cargarlo y aplicarlo a nuevos conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardado del modelo ya entrenado\n",
    "xgb.save(???, ???)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
